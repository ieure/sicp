<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<?xml version="1.0" encoding="utf-8"?><html xmlns="http://www.w3.org/1999/xhtml" xmlns:ops="http://www.idpf.org/2007/ops">
<!-- Generated from TeX source by tex2page, v 4o,
     (c) Dorai Sitaram, http://www.cs.rice.edu/~dorai/tex2page --><head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta http-equiv="Content-Type: text/html; charset=utf-8">
<title>Structure and Interpretation of Computer Programs</title>
<link rel="stylesheet" type="text/css" href="book-Z-C.css" title="default">
</head>
<body><a name="%_sec_1.2" id="%_sec_1.2"></a><h2><a href="book-Z-H-4.html#%_toc_%_sec_1.2">1.2  Procedures and the Processes They Generate</a></h2>
<p></p>
<p>We have now considered the elements of programming: We have usedprimitive arithmetic operations, we have combined these operations, andwe have abstracted these composite operations by defining them as compoundprocedures.  But that is not enough to enable us to say that we knowhow to program.  Our situation is analogous to that of someone who haslearned the rules for how the pieces move in chess but knows nothingof typical openings, tactics, or strategy.  Like the novice chessplayer, we don't yet know the common patterns of usage in the domain.We lack the knowledge of which moves are worth making (whichprocedures are worth defining).  We lack the experience to predict theconsequences of making a move (executing a procedure).</p>
<p>The ability to visualize the consequences of the actions underconsideration is crucial to becoming an expert programmer, just as itis in any synthetic, creative activity.  In becoming an expertphotographer, for example, one must learn how to look at a scene andknow how dark each region will appear on a print for each possiblechoice of exposure and development conditions.  Only then can onereason backward, planning framing, lighting, exposure, and developmentto obtain the desired effects.  So it is with programming, where weare planning the course of action to be taken by a process and wherewe control the process by means of a program.  To become experts, wemust learn to visualize the processes generated by various types ofprocedures.  Only after we have developed such a skill can we learnto reliably construct programs that exhibit the desired behavior.</p>
<p><a name="%_idx_630" id="%_idx_630"></a><a name="%_idx_632" id="%_idx_632"></a><a name="%_idx_634" id="%_idx_634"></a>A procedure is a pattern for the <em>local evolution</em> of acomputational process.  It specifies how each stage of the process isbuilt upon the previous stage.  We would like to be able to makestatements about the overall, or <em>global</em>, behavior of aprocess whose local evolution has been specified by a procedure.  Thisis very difficult to do in general, but we can at least try todescribe some typical patterns of process evolution.</p>
<p>In this section we will examine some common “shapes” for processesgenerated by simple procedures.  We will also investigate therates at which these processes consume the important computationalresources of time and space.  The procedures we will considerare very simple.  Their role is like that played by test patterns inphotography: as oversimplified prototypical patterns, rather thanpractical examples in their own right.</p>
<p><a name="%_sec_1.2.1" id="%_sec_1.2.1"></a></p>
<h3><a href="book-Z-H-4.html#%_toc_%_sec_1.2.1">1.2.1  Linear Recursion and Iteration</a></h3>
<p><a name="%_idx_636" id="%_idx_636"></a><a name="%_idx_638" id="%_idx_638"></a><a name="%_fig_1.3" id="%_fig_1.3"></a></p>
<p></p>
<div align="left"><table width="100%">
<tr><td><img src="images/ch1-Z-G-7.gif" border="0"></td></tr>
<caption align="bottom"><div align="left">
<b>Figure 1.3:</b>  A linear recursive process for computing 6!.</div></caption>
<tr><td></td></tr>
</table></div>
<p></p>
<p><a name="%_idx_640" id="%_idx_640"></a>We begin by considering the factorial function, defined by</p>
<p></p>
<p><em>n</em>! = <em>n</em> · (<em>n</em> - 1) · (<em>n</em> - 2) ⋯ 3 · 2 · 1</p>There are many ways to compute factorials.  One way is to make use ofthe observation that <em>n</em>! is equal to <em>n</em> times (<em>n</em> - 1)! forany positive integer <em>n</em>:<p></p>
<p><em>n</em>! = <em>n</em> · [(<em>n</em> - 1) · (<em>n</em> - 2) ⋯ 3 · 2 · 1] = <em>n</em> · (<em>n</em> - 1)!</p>Thus, we can compute <em>n</em>! by computing (<em>n</em> - 1)! and multiplying theresult by <em>n</em>.  If we add the stipulation that 1! is equal to 1,this observation translates directly into a procedure:<p></p>
<p></p>
<p><pre><a name="%_idx_642" id="%_idx_642"></a>(define (factorial n)
  (if (= n 1)
      1
      (* n (factorial (- n 1)))))
</pre></p>
<p></p>
<p><a name="%_idx_644" id="%_idx_644"></a>We can use the substitution model ofsection <a href="book-Z-H-10.html#%_sec_1.1.5">1.1.5</a> to watch this procedure in actioncomputing 6!, as shown in figure <a href="#%_fig_1.3">1.3</a>.</p>
<p>Now let's take a different perspective on computing factorials.  Wecould describe a rule for computing <em>n</em>! by specifying that wefirst multiply 1 by 2, then multiply the result by 3, then by 4,and so on until we reach <em>n</em>.More formally, we maintain a running product, together with a counterthat counts from 1 up to <em>n</em>.  We can describe the computation bysaying that the counter and the product simultaneously change from onestep to the next according to the rule</p>
<p></p>
<p></p>
<p>product  ⟵  counter  ·  product </p>
<p></p>
<p></p>
<p>counter  ⟵  counter  +  1</p>
<p></p>
<p></p>
<p></p>
<p>and stipulating that <em>n</em>! is the value of the product whenthe counter exceeds <em>n</em>.</p>
<p><a name="%_fig_1.4" id="%_fig_1.4"></a></p>
<p></p>
<div align="left"><table width="100%">
<tr><td><img src="images/ch1-Z-G-10.gif" border="0"></td></tr>
<caption align="bottom"><div align="left">
<b>Figure 1.4:</b>  A linear iterative process for computing 6!.</div></caption>
<tr><td></td></tr>
</table></div>
<p></p>
<p>Once again, we can recast our description as a procedure for computingfactorials:<a name="call_footnote_Temp_46" href="#footnote_Temp_46" id="call_footnote_Temp_46"><sup><small>29</small></sup></a></p>
<p></p>
<p></p>
<p><pre><a name="%_idx_646" id="%_idx_646"></a>(define (factorial n)
  (fact-iter 1 1 n))

(define (fact-iter product counter max-count)
  (if (&gt; counter max-count)
      product
      (fact-iter (* counter product)
                 (+ counter 1)
                 max-count)))
</pre></p>
<p></p>
<p></p>
<p>As before, we can use the substitution model to visualize the processof computing 6!, as shown in figure <a href="#%_fig_1.4">1.4</a>.</p>
<p>Compare the two processes.  From one point of view, they seem hardlydifferent at all.  Both compute the same mathematical function on thesame domain, and each requires a number of steps proportional to <em>n</em>to compute <em>n</em>!.  Indeed, both processes even carry out the samesequence of multiplications, obtaining the same sequence of partialproducts.  On the other hand, when we consider the <a name="%_idx_648" id="%_idx_648"></a><a name="%_idx_650" id="%_idx_650"></a>“shapes” of thetwo processes, we find that they evolve quite differently.</p>
<p>Consider the first process.  The substitution model reveals a shape ofexpansion followed by contraction, indicated by the arrow infigure <a href="#%_fig_1.3">1.3</a>.  The expansion occurs as theprocess builds up a chain of <a name="%_idx_652" id="%_idx_652"></a><em>deferred operations</em> (in this case,a chain of multiplications).  The contraction occurs asthe operations areactually performed.  This type of process, characterized by a chain ofdeferred operations, is called a <a name="%_idx_654" id="%_idx_654"></a><a name="%_idx_656" id="%_idx_656"></a><em>recursive process</em>.  Carryingout this process requires that the interpreter keep track of theoperations to be performed later on.  In the computation of <em>n</em>!,the length of the chain of deferred multiplications, and hence the amountof information needed to keep track of it, <a name="%_idx_658" id="%_idx_658"></a>grows linearly with <em>n</em>(is proportional to <em>n</em>), just like the number of steps.<a name="%_idx_660" id="%_idx_660"></a><a name="%_idx_662" id="%_idx_662"></a><a name="%_idx_664" id="%_idx_664"></a>Such a process is called a <em>linear recursive process</em>.</p>
<p>By contrast, the second process does not grow and shrink.  At eachstep, all we need to keep track of, for any <em>n</em>, are the currentvalues of the variables <code>product</code>, <code>counter</code>, and <code>max-count</code>.  We call this an <a name="%_idx_666" id="%_idx_666"></a><a name="%_idx_668" id="%_idx_668"></a><em>iterative process</em>.  In general, aniterative process is one whose state can be summarized by a fixednumber of <a name="%_idx_670" id="%_idx_670"></a><em>state variables</em>, together with a fixed rule thatdescribes how the state variables should be updated as the processmoves from state to state and an (optional) end test that specifiesconditions under which the process should terminate.  In computing<em>n</em>!, the number of steps required grows linearly with <em>n</em>.  Such a process iscalled a <a name="%_idx_672" id="%_idx_672"></a><a name="%_idx_674" id="%_idx_674"></a><a name="%_idx_676" id="%_idx_676"></a><em>linear iterative process</em>.</p>
<p>The contrast between the two processes can be seen in another way.  Inthe iterative case, the program variables provide a completedescription of the state of the process at any point.  If we stoppedthe computation between steps, all we would need to do to resume thecomputation is to supply the interpreter with the values of the threeprogram variables.  Not so with the recursive process.  In this casethere is some additional “hidden” information, maintained by theinterpreter and not contained in the program variables, whichindicates “where the process is” in negotiating the chain ofdeferred operations.  The longer the chain, the more information mustbe maintained.<a name="call_footnote_Temp_47" href="#footnote_Temp_47" id="call_footnote_Temp_47"><sup><small>30</small></sup></a></p>
<p>In contrasting iteration and recursion, we must be careful not toconfuse the notion of a <a name="%_idx_680" id="%_idx_680"></a><a name="%_idx_682" id="%_idx_682"></a>recursive <em>process</em> with the notion of arecursive <em>procedure</em>.  When we describe a procedure as recursive,we are referring to the syntactic fact that the procedure definitionrefers (either directly or indirectly) to the procedure itself.  Butwhen we describe a process as following a pattern that is, say,linearly recursive, we are speaking about how the process evolves, notabout the syntax of how a procedure is written.  It may seemdisturbing that we refer to a recursive procedure such as <code>fact-iter</code> as generating an iterative process.  However, the processreally is iterative: Its state is captured completely by its threestate variables, and an interpreter need keep track of only threevariables in order to execute the process.</p>
<p>One reason that the distinction between process and procedure may beconfusing is that most implementations of common languages (including<a name="%_idx_684" id="%_idx_684"></a><a name="%_idx_686" id="%_idx_686"></a><a name="%_idx_688" id="%_idx_688"></a>Ada, Pascal, and C) are designed in such a way that theinterpretation of any recursive procedure consumes an amount of memorythat grows with the number of procedure calls, even when the processdescribed is, in principle, iterative.  As a consequence, theselanguages can describe iterative processes only by resorting tospecial-purpose <a name="%_idx_690" id="%_idx_690"></a>“looping constructs” such as <code>do</code>, <code>repeat</code>,<code>until</code>, <code>for</code>, and <code>while</code>.  The implementation of Schemewe shall consider in chapter 5 does not share this defect.  It willexecute an iterative process in constant space, even if the iterativeprocess is described by a recursive procedure.  An implementation withthis property is called <a name="%_idx_692" id="%_idx_692"></a><em>tail-recursive</em>.  With a tail-recursiveimplementation, <a name="%_idx_694" id="%_idx_694"></a>iteration can be expressed using the ordinaryprocedure call mechanism, so that special iteration constructs areuseful only as <a name="%_idx_696" id="%_idx_696"></a>syntactic sugar.<a name="call_footnote_Temp_48" href="#footnote_Temp_48" id="call_footnote_Temp_48"><sup><small>31</small></sup></a></p>
<p></p>
<p><a name="%_thm_1.9" id="%_thm_1.9"></a><b>Exercise 1.9.</b>  Each of the following two procedures defines a method for adding twopositive integers in terms of the procedures <code>inc</code>,which increments its argument by 1, and <code>dec</code>, which decrementsits argument by 1.</p>
<p></p>
<p></p>
<p><pre>(define (+ a b)
  (if (= a 0)
      b
      (inc (+ (dec a) b))))

(define (+ a b)
  (if (= a 0)
      b
      (+ (dec a) (inc b))))
</pre></p>
<p></p>
<p>Using the substitution model, illustrate the process generated by eachprocedure in evaluating <code>(+ 4 5)</code>.  Are these processesiterative or recursive?</p>
<p></p>
<p></p>
<p><a name="%_thm_1.10" id="%_thm_1.10"></a><b>Exercise 1.10.</b>  <a name="%_idx_708" id="%_idx_708"></a><a name="%_idx_710" id="%_idx_710"></a>The following procedure computes a mathematical function calledAckermann's function.</p>
<p></p>
<p></p>
<p><pre>(define (A x y)
  (cond ((= y 0) 0)
        ((= x 0) (* 2 y))
        ((= y 1) 2)
        (else (A (- x 1)
                 (A x (- y 1))))))
</pre></p>
<p></p>
<p>What are the values of the following expressions?</p>
<p></p>
<p></p>
<p><pre>(A 1 10)

(A 2 4)

(A 3 3)
</pre></p>
<p></p>
<p>Consider the following procedures, where <code>A</code> is the proceduredefined above:</p>
<p></p>
<p><pre>(define (f n) (A 0 n))

(define (g n) (A 1 n))

(define (h n) (A 2 n))

(define (k n) (* 5 n n))
</pre></p>
<p></p>
<p>Give concise mathematical definitions for the functions computed bythe procedures <code>f</code>, <code>g</code>, and <code>h</code> for positive integervalues of <em>n</em>.  For example, <code>(k n)</code> computes 5<em>n</em><sup>2</sup>.</p>
<p></p>
<p><a name="%_sec_1.2.2" id="%_sec_1.2.2"></a></p>
<h3><a href="book-Z-H-4.html#%_toc_%_sec_1.2.2">1.2.2  Tree Recursion</a></h3>
<p><a name="%_idx_712" id="%_idx_712"></a><a name="%_idx_714" id="%_idx_714"></a><a name="%_idx_716" id="%_idx_716"></a>Another common pattern of computation is called <em>tree recursion</em>.As an example, consider computing the sequence of <a name="%_idx_718" id="%_idx_718"></a>Fibonacci numbers,in which each number is the sum of the preceding two:</p>
<p></p>
<p>0, 1, 1, 2, 3, 5, 8, 13, 21, …</p>In general, the Fibonacci numbers can be defined by the rule<p></p>
<div align="left"><img src="images/ch1-Z-G-12.gif" border="0"></div>
<p>We can immediately translate this definition into a recursiveprocedure for computing Fibonacci numbers:</p>
<p></p>
<p></p>
<p><pre><a name="%_idx_720" id="%_idx_720"></a>(define (fib n)
  (cond ((= n 0) 0)
        ((= n 1) 1)
        (else (+ (fib (- n 1))
                 (fib (- n 2))))))
</pre></p>
<p></p>
<p></p>
<p><a name="%_fig_1.5" id="%_fig_1.5"></a></p>
<p></p>
<div align="left"><table width="100%">
<tr><td><img src="images/ch1-Z-G-13.gif" border="0"></td></tr>
<caption align="bottom"><div align="left">
<b>Figure 1.5:</b>  The tree-recursive process generated in computing <code>(fib 5)</code>.</div></caption>
<tr><td></td></tr>
</table></div>
<p></p>
<p>Consider the pattern of this computation.  To compute <code>(fib 5)</code>,we compute <code>(fib 4)</code> and <code>(fib 3)</code>.  To compute <code>(fib 4)</code>,we compute <code>(fib 3)</code> and <code>(fib 2)</code>.  In general, the evolvedprocess looks like a tree, as shown in figure <a href="#%_fig_1.5">1.5</a>.Notice that the branches split into two at each level (except at thebottom); this reflects the fact that the <code>fib</code> procedure callsitself twice each time it is invoked.</p>
<p>This procedure is instructive as a prototypical tree recursion, but itis a terrible way to compute Fibonacci numbers because it does so muchredundant computation.  Notice in figure <a href="#%_fig_1.5">1.5</a> thatthe entire computation of <code>(fib 3)</code> – almost half the work – isduplicated.  In fact, it is not hard to show that the number of timesthe procedure will compute <code>(fib 1)</code> or <code>(fib 0)</code> (the numberof leaves in the above tree, in general) is precisely<em>F</em><em>i</em><em>b</em>(<em>n</em> + 1).  To get an idea of how bad this is, one can show that thevalue of  <em>F</em><em>i</em><em>b</em>(<em>n</em>) <a name="%_idx_722" id="%_idx_722"></a>grows exponentially with <em>n</em>.  More precisely(see exercise <a href="#%_thm_1.13">1.13</a>),  <em>F</em><em>i</em><em>b</em>(<em>n</em>) is the closestinteger to <em>φ</em><sup><em>n</em></sup> /√5, where</p><p><em>φ</em> = (1 + √5)/2 ≈ 1.6180</p><p>is the <a name="%_idx_724" id="%_idx_724"></a><em>golden ratio</em>, which satisfies the equation</p><p><em>φ</em><sup>2</sup> = <em>φ</em> + 1</p><p>Thus, the process uses a number of steps that grows exponentiallywith the input.  On the other hand, the space required grows onlylinearly with the input, because we need keep track only of whichnodes are above us in the tree at any point in the computation.  Ingeneral, the number of steps required by a tree-recursive process will beproportional to the number of nodes in the tree, while the spacerequired will be proportional to the maximum depth of the tree.</p>
<p>We can also formulate an iterative process for computing theFibonacci numbers.  The idea is to use a pair of integers <em>a</em> and<em>b</em>, initialized to  <em>F</em><em>i</em><em>b</em>(1) = 1 and  <em>F</em><em>i</em><em>b</em>(0) = 0,and to repeatedly apply the simultaneoustransformations</p>
<p>    <em>a</em> ⟵ <em>a</em> + <em>b</em>
<em>b</em> ⟵ <em>a</em></p>It is not hard to show that, after applying this transformation <em>n</em>times, <em>a</em> and <em>b</em> will be equal, respectively, to  <em>F</em><em>i</em><em>b</em>(<em>n</em> + 1) and <em>F</em><em>i</em><em>b</em>(<em>n</em>).  Thus, we can compute Fibonacci numbers iteratively usingthe procedure<p></p>
<p></p>
<p><pre><a name="%_idx_726" id="%_idx_726"></a>(define (fib n)
  (fib-iter 1 0 n))

(define (fib-iter a b count)
  (if (= count 0)
      b
      (fib-iter (+ a b) a (- count 1))))
</pre></p>
<p></p>
<p>This second method for computing  <em>F</em><em>i</em><em>b</em>(<em>n</em>) is a linear iteration.  Thedifference in number of steps required by the two methods – one linear in <em>n</em>,one growing as fast as  <em>F</em><em>i</em><em>b</em>(<em>n</em>) itself – is enormous, even forsmall inputs.</p>
<p>One should not conclude from this that tree-recursive processes areuseless.  When we consider processes that operate on hierarchicallystructured data rather than numbers, we will find that tree recursionis a natural and powerful tool.<a name="call_footnote_Temp_51" href="#footnote_Temp_51" id="call_footnote_Temp_51"><sup><small>32</small></sup></a> But even in numerical operations,tree-recursive processes can be useful in helping us to understand anddesign programs.  For instance, although the first <code>fib</code> procedureis much less efficient than the second one, it is morestraightforward, being little more than a translation into Lisp of thedefinition of the Fibonacci sequence.  To formulate the iterativealgorithm required noticing that the computation could be recast as aniteration with three state variables.</p>
<p><a name="%_sec_Temp_52" id="%_sec_Temp_52"></a></p>
<h4><a href="book-Z-H-4.html#%_toc_%_sec_Temp_52">Example: Counting change</a></h4>
<p><a name="%_idx_728" id="%_idx_728"></a>It takes only a bit of cleverness to come up with the iterativeFibonacci algorithm.  In contrast, consider thefollowing problem: How many different ways can we make change of $ 1.00,given half-dollars, quarters, dimes, nickels, and pennies?  Moregenerally, can we write a procedure to compute the number of ways tochange any given amount of money?</p>
<p>This problem has a simple solution as a recursive procedure.  Supposewe think of the types of coins available as arranged in some order.Then the following relation holds:</p>
<p></p>
<p></p>
<p>The number of ways to change amount <em>a</em> using <em>n</em> kinds of coins equals</p>
<p></p>
<p></p>
<ul>
<li>the number of ways to change amount <em>a</em> using all but the firstkind of coin, plus<p></p>
</li>
<li>the number of ways to change amount <em>a</em> - <em>d</em> using all <em>n</em> kinds ofcoins, where <em>d</em> is the denomination of the first kind of coin.</li>
</ul>
<p></p>
<p>To see why this is true, observe that the ways to make change can bedivided into two groups: those that do not use any of the first kindof coin, and those that do.  Therefore, the total number of ways tomake change for some amount is equal to the number of ways to makechange for the amount without using any of the first kind of coin,plus the number of ways to make change assuming that we do use thefirst kind of coin.  But the latter number is equal to the number ofways to make change for the amount that remains after using a coin ofthe first kind.</p>
<p>Thus, we can recursively reduce the problem of changing a given amountto the problem of changing smaller amounts using fewer kinds of coins.Consider this reduction rule carefully, and convince yourself that wecan use it to describe an algorithm if we specify the followingdegenerate cases:<a name="call_footnote_Temp_53" href="#footnote_Temp_53" id="call_footnote_Temp_53"><sup><small>33</small></sup></a></p>
<p></p>
<p></p>
<ul>
<li>If <em>a</em> is exactly 0, we should count that as 1 way to make change.<p></p>
</li>
<li>If <em>a</em> is less than 0, we should count that as 0 ways to make change.<p></p>
</li>
<li>If <em>n</em> is 0, we should count that as 0 ways to make change.</li>
</ul>
<p></p>
<p>We can easily translate this description into a recursiveprocedure:</p>
<p></p>
<p></p>
<p><pre><a name="%_idx_730" id="%_idx_730"></a>(define (count-change amount)
  (cc amount 5))
(define (cc amount kinds-of-coins)
  (cond ((= amount 0) 1)
        ((or (&lt; amount 0) (= kinds-of-coins 0)) 0)
        (else (+ (cc amount
                     (- kinds-of-coins 1))
                 (cc (- amount
                        (first-denomination kinds-of-coins))
                     kinds-of-coins)))))
(define (first-denomination kinds-of-coins)
  (cond ((= kinds-of-coins 1) 1)
        ((= kinds-of-coins 2) 5)
        ((= kinds-of-coins 3) 10)
        ((= kinds-of-coins 4) 25)
        ((= kinds-of-coins 5) 50)))
</pre></p>
<p></p>
<p>(The <code>first-denomination</code> procedure takes as input the number ofkinds of coins available and returns the denomination of the firstkind.  Here we are thinking of the coins as arranged in order fromlargest to smallest, but any order would do as well.)  We can nowanswer our original question about changing a dollar:</p>
<p></p>
<p></p>
<p><pre>(count-change 100)
<i>292</i>
</pre></p>
<p></p>
<p></p>
<p><code>Count-change</code> generates a tree-recursive process withredundancies similar to those in our first implementation of <code>fib</code>.  (It will take quite a while for that 292 to be computed.)  Onthe other hand, it is not obvious how to design a better algorithmfor computing the result, and we leave this problem as a challenge.The observation that a <a name="%_idx_732" id="%_idx_732"></a>tree-recursive process may be highlyinefficient but often easy to specify and understand has led people topropose that one could get the best of both worlds by designing a“smart compiler” that could transform tree-recursive procedures intomore efficient procedures that compute the same result.<a name="call_footnote_Temp_54" href="#footnote_Temp_54" id="call_footnote_Temp_54"><sup><small>34</small></sup></a></p>
<p></p>
<p><a name="%_thm_1.11" id="%_thm_1.11"></a><b>Exercise 1.11.</b>  A function <em>f</em> is defined by the rule that <em>f</em>(<em>n</em>) = <em>n</em> if <em>n</em>&lt;3 and<em>f</em>(<em>n</em>) = <em>f</em>(<em>n</em> - 1) + 2<em>f</em>(<em>n</em> - 2) + 3<em>f</em>(<em>n</em> - 3) if <em>n</em><u>&gt;</u> 3.  Write a procedure thatcomputes <em>f</em> by means of a recursive process.  Write a procedure thatcomputes <em>f</em> by means of an iterative process.</p>
<p></p>
<p></p>
<p><a name="%_thm_1.12" id="%_thm_1.12"></a><b>Exercise 1.12.</b>  <a name="%_idx_738" id="%_idx_738"></a>The following pattern of numbers is called<em>Pascal's triangle</em>.</p><pre>    1   1 1  1 2 1 1 3 3 11 4 6 4 1    …</pre><p>The numbers at the edge of the triangle are all 1, andeach number inside the triangle is the sum of the two numbers above it.<a name="call_footnote_Temp_57" href="#footnote_Temp_57" id="call_footnote_Temp_57"><sup><small>35</small></sup></a>Write a procedure that computes elements of Pascal's triangle by meansof a recursive process.</p>
<p></p>
<p></p>
<p><a name="%_thm_1.13" id="%_thm_1.13"></a><b>Exercise 1.13.</b>  Prove that  <em>F</em><em>i</em><em>b</em>(<em>n</em>) is the closest integer to <em>φ</em><sup><em>n</em></sup>/√5,where <em>φ</em> =  (1 + √5)/2.  Hint: Let <em>ψ</em> =  (1 - √5)/2.  Useinduction and the definition of the Fibonacci numbers (seesection <a href="#%_sec_1.2.2">1.2.2</a>) to prove that  <em>F</em><em>i</em><em>b</em>(<em>n</em>) = (<em>φ</em><sup><em>n</em></sup> - <em>ψ</em><sup><em>n</em></sup>)/√5.</p>
<p></p>
<p><a name="%_sec_1.2.3" id="%_sec_1.2.3"></a></p>
<h3><a href="book-Z-H-4.html#%_toc_%_sec_1.2.3">1.2.3  Orders of Growth</a></h3>
<p><a name="%_idx_752" id="%_idx_752"></a>The previous examples illustrate that processes can differconsiderably in the rates at which they consume computationalresources.  One convenient way to describe this difference is to usethe notion of <a name="%_idx_754" id="%_idx_754"></a><em>order of growth</em> to obtain a gross measure of the<a name="%_idx_756" id="%_idx_756"></a>resources required by a process as the inputs become larger.</p>
<p>Let <em>n</em> be a parameter that measures the size of the problem, and let<em>R</em>(<em>n</em>) be the amount of resources the process requires for a problemof size <em>n</em>.  In our previous examples we took <em>n</em> to be the numberfor which a given function is to be computed, but there are otherpossibilities.  For instance, if our goal is to compute anapproximation to the square root of a number, we might take <em>n</em> to bethe number of digits accuracy required.  For matrix multiplication wemight take <em>n</em> to be the number of rows in the matrices.  In generalthere are a number of properties of the problem with respect to whichit will be desirable to analyze a given process.  Similarly, <em>R</em>(<em>n</em>)might measure the number of internal storage registers used, thenumber of elementary machine operations performed, and so on.  Incomputers that do only a fixed number of operations at a time, thetime required will be proportional to the number of elementary machineoperations performed.</p>
<p><a name="%_idx_758" id="%_idx_758"></a><a name="%_idx_760" id="%_idx_760"></a>We say that <em>R</em>(<em>n</em>) has order of growth θ(<em>f</em>(<em>n</em>)), written<em>R</em>(<em>n</em>) = θ(<em>f</em>(<em>n</em>)) (pronounced “theta of <em>f</em>(<em>n</em>)”), if there arepositive constants <em>k</em><sub>1</sub> and <em>k</em><sub>2</sub> independent of <em>n</em> such that</p>
<p><em>k</em><sub>1</sub><em>f</em>(<em>n</em>) ≤ <em>R</em>(<em>n</em>) ≤ <em>k</em><sub>2</sub><em>f</em>(<em>n</em>)</p>for any sufficiently large value of <em>n</em>.  (In otherwords, for large <em>n</em>, the value <em>R</em>(<em>n</em>) is sandwiched between <em>k</em><sub>1</sub><em>f</em>(<em>n</em>)and <em>k</em><sub>2</sub><em>f</em>(<em>n</em>).)<p><a name="%_idx_762" id="%_idx_762"></a><a name="%_idx_764" id="%_idx_764"></a><a name="%_idx_766" id="%_idx_766"></a>For instance, with the linear recursive process for computingfactorial described in section <a href="#%_sec_1.2.1">1.2.1</a> thenumber of steps grows proportionally to the input <em>n</em>.  Thus, thesteps required for this process grows as θ(<em>n</em>).  We also sawthat the space required grows as θ(<em>n</em>).  For the <a name="%_idx_768" id="%_idx_768"></a><a name="%_idx_770" id="%_idx_770"></a><a name="%_idx_772" id="%_idx_772"></a>iterativefactorial, the number of steps is still θ(<em>n</em>) but the space isθ(1) – that is, constant.<a name="call_footnote_Temp_59" href="#footnote_Temp_59" id="call_footnote_Temp_59"><sup><small>36</small></sup></a> The <a name="%_idx_774" id="%_idx_774"></a><a name="%_idx_776" id="%_idx_776"></a><a name="%_idx_778" id="%_idx_778"></a>tree-recursive Fibonacci computation requiresθ(<em>φ</em><sup><em>n</em></sup>) steps and space θ(<em>n</em>), where <em>φ</em> is thegolden ratio described in section <a href="#%_sec_1.2.2">1.2.2</a>.</p>
<p>Orders of growth provide only a crude description of the behavior of aprocess.  For example, a process requiring <em>n</em><sup>2</sup> steps and a processrequiring 1000<em>n</em><sup>2</sup> steps and a process requiring 3<em>n</em><sup>2</sup> + 10<em>n</em> + 17 stepsall have θ(<em>n</em><sup>2</sup>) order of growth.  On the other hand, order ofgrowth provides a useful indication of how we may expect the behaviorof the process to change as we change the size of the problem.  For a<a name="%_idx_780" id="%_idx_780"></a>θ(<em>n</em>) (linear) process, doubling the size will roughly double the amountof resources used.  For an <a name="%_idx_782" id="%_idx_782"></a>exponential process, each increment inproblem size will multiply the resource utilization by a constantfactor.  In the remainder of section <a href="#%_sec_1.2">1.2</a>we will examine twoalgorithms whose order of growth is <a name="%_idx_784" id="%_idx_784"></a>logarithmic, so that doubling theproblem size increases the resource requirement by a constant amount.</p>
<p></p>
<p><a name="%_thm_1.14" id="%_thm_1.14"></a><b>Exercise 1.14.</b>  Draw the tree illustrating the process generated by the <code>count-change</code> procedure of section <a href="#%_sec_1.2.2">1.2.2</a> in makingchange for 11 cents.  What are the orders of growth of the space andnumber of steps used by this process as the amount to be changedincreases?</p>
<p></p>
<p></p>
<p><a name="%_thm_1.15" id="%_thm_1.15"></a><b>Exercise 1.15.</b>  <a name="%_idx_786" id="%_idx_786"></a>The sine of an angle (specified inradians) can be computed by making use of the approximation<code>sin</code> <em>x</em> ≈  <em>x</em>if <em>x</em> issufficiently small, and the trigonometric identity</p>
<p></p>
<div align="left"><img src="images/ch1-Z-G-19.gif" border="0"></div>
<p>to reduce the size of the argument of <code>sin</code>.  (Forpurposes of this exercise an angle is considered “sufficientlysmall” if its magnitude is not greater than 0.1 radians.) Theseideas are incorporated in the following procedures:</p>
<p></p>
<p></p>
<p><pre><a name="%_idx_788" id="%_idx_788"></a>(define (cube x) (* x x x))
(define (p x) (- (* 3 x) (* 4 (cube x))))
(define (sine angle)
   (if (not (&gt; (abs angle) 0.1))
       angle
       (p (sine (/ angle 3.0)))))
</pre></p>
<p></p>
<p></p>
<p>a.  How many times is the procedure <code>p</code>applied when <code>(sine 12.15)</code> is evaluated?</p>
<p>b.  What is the order of growth in space and number of steps (as afunction of <em>a</em>) used by the process generated by the <code>sine</code>procedure when <code>(sine a)</code> is evaluated?</p>
<p></p>
<p><a name="%_sec_1.2.4" id="%_sec_1.2.4"></a></p>
<h3><a href="book-Z-H-4.html#%_toc_%_sec_1.2.4">1.2.4  Exponentiation</a></h3>
<p><a name="%_idx_790" id="%_idx_790"></a>Consider the problem of computing the exponential of a given number.We would like a procedure that takes as arguments a base <em>b</em> and apositive integer exponent <em>n</em> and computes <em>b</em><sup><em>n</em></sup>.  One way to do thisis via the recursive definition</p>
<p>    <em>b<sup>n</sup></em> = <em>b</em> · <em>b</em><sup><em>n</em>-1</sup>
<em>b</em><sup>0</sup> = 1</p><p>which translates readily into the procedure </p>
<p></p>
<p></p>
<p><pre><a name="%_idx_792" id="%_idx_792"></a>(define (expt b n)
  (if (= n 0)
      1
      (* b (expt b (- n 1)))))
</pre></p>
<p></p>
<p>This is a linear recursive process, which requires θ(<em>n</em>) stepsand θ(<em>n</em>) space.  Just as with factorial, we can readilyformulate an equivalent linear iteration:</p>
<p></p>
<p></p>
<p><pre><a name="%_idx_794" id="%_idx_794"></a>(define (expt b n)
  (expt-iter b n 1))

(define (expt-iter b counter product)
  (if (= counter 0)
      product
      (expt-iter b
                (- counter 1)
                (* b product)))) 
</pre></p>
<p></p>
<p>This version requires θ(<em>n</em>) steps and θ(1) space.</p>
<p><a name="%_idx_796" id="%_idx_796"></a>We can compute exponentials in fewer steps by using successivesquaring.  For instance, rather than computing <em>b</em><sup>8</sup> as</p>
<p><em>b</em> · (<em>b</em> · (<em>b</em> · (<em>b</em> · (<em>b</em> · (<em>b</em> · (<em>b</em> · <em>b</em>))))))</p>we can compute it using three multiplications:<p>    <em>b</em><sup>2</sup> = <em>b</em> · <em>b</em>
<em>b</em><sup>4</sup> = <em>b</em><sup>2</sup> · <em>b</em><sup>2</sup>
<em>b</em><sup>8</sup> = <em>b</em><sup>4</sup> · <em>b</em><sup>4</sup></p>This method works fine for exponents that are powers of 2.  We canalso take advantage of successive squaring in computing exponentialsin general if we use the rule<p>    <em>b<sup>n</sup></em> = (<em>b</em><sup><em>n</em>/2</sup>)<sup>2</sup>          if <em>n</em> is even
<em>b<sup>n</sup></em> = <em>b</em> · <em>b</em><sup><em>n</em>-1</sup>         if <em>n</em> is odd</p><p>We can express this method as a procedure:</p>
<p></p>
<p></p>
<p><pre><a name="%_idx_798" id="%_idx_798"></a>(define (fast-expt b n)
  (cond ((= n 0) 1)
        ((even? n) (square (fast-expt b (/ n 2))))
        (else (* b (fast-expt b (- n 1))))))
</pre></p>
<p></p>
<p>where the predicate to test whether an integer is even is defined in terms ofthe <a name="%_idx_800" id="%_idx_800"></a><a name="%_idx_802" id="%_idx_802"></a>primitive procedure <code>remainder</code> by</p>
<p></p>
<p></p>
<p><pre><a name="%_idx_804" id="%_idx_804"></a>(define (even? n)
  (= (remainder n 2) 0))
</pre></p>
<p></p>
<p><a name="%_idx_806" id="%_idx_806"></a><a name="%_idx_808" id="%_idx_808"></a>The process evolved by <code>fast-expt</code> grows logarithmically with <em>n</em>in both space and number of steps.  To see this, observe thatcomputing <em>b</em><sup>2<em>n</em></sup> using <code>fast-expt</code> requires only one moremultiplication than computing <em>b</em><sup><em>n</em></sup>.  The size of the exponent we cancompute therefore doubles (approximately) with every newmultiplication we are allowed.  Thus, the number of multiplicationsrequired for an exponent of <em>n</em> grows about as fast as the logarithmof <em>n</em> to the base 2.  The process has θ(<code>log</code> <em>n</em>)growth.<a name="call_footnote_Temp_62" href="#footnote_Temp_62" id="call_footnote_Temp_62"><sup><small>37</small></sup></a></p>
<p>The difference between θ(<code>log</code> <em>n</em>) growth and θ(<em>n</em>) growthbecomes striking as <em>n</em> becomes large.  For example, <code>fast-expt</code>for <em>n</em> = 1000 requires only 14 multiplications.<a name="call_footnote_Temp_63" href="#footnote_Temp_63" id="call_footnote_Temp_63"><sup><small>38</small></sup></a> It is also possible to use the idea ofsuccessive squaring to devise an iterative algorithm that computesexponentials with a logarithmic number of steps(see exercise <a href="#%_thm_1.16">1.16</a>), although, as is oftenthe case with iterative algorithms, this is not written down sostraightforwardly as the recursive algorithm.<a name="call_footnote_Temp_64" href="#footnote_Temp_64" id="call_footnote_Temp_64"><sup><small>39</small></sup></a></p>
<p></p>
<p><a name="%_thm_1.16" id="%_thm_1.16"></a><b>Exercise 1.16.</b>  Design a procedure that evolves an iterative exponentiation processthat uses successive squaring and uses a logarithmic number of steps,as does <code>fast-expt</code>.  (Hint: Using the observation that(<em>b</em><sup><em>n</em>/2</sup>)<sup>2</sup>  = (<em>b</em><sup>2</sup>)<sup><em>n</em>/2</sup>, keep, along with the exponent <em>n</em> and thebase <em>b</em>, an additional state variable <em>a</em>, and define the statetransformation in such a way that the product <em>a</em> <em>b</em><sup><em>n</em></sup> is unchangedfrom state to state.  At the beginning of the process <em>a</em> is taken tobe 1, and the answer is given by the value of <em>a</em> at the end of theprocess.  In general, the technique of defining an <a name="%_idx_816" id="%_idx_816"></a><em>invariantquantity</em> that remains unchanged from state to state is a powerful wayto think about the <a name="%_idx_818" id="%_idx_818"></a>design of iterative algorithms.)</p>
<p></p>
<p></p>
<p><a name="%_thm_1.17" id="%_thm_1.17"></a><b>Exercise 1.17.</b>  The exponentiation algorithms in this section are based on performingexponentiation by means of repeated multiplication.  In a similar way,one can perform integer multiplication by means of repeated addition.The following multiplication procedure (in which it is assumed thatour language can only add, not multiply) is analogous to the <code>expt</code> procedure:</p>
<p></p>
<p></p>
<p><pre>(define (* a b)
  (if (= b 0)
      0
      (+ a (* a (- b 1)))))
</pre></p>
<p></p>
<p>This algorithm takes a number of steps that is linear in <code>b</code>.Now suppose we include, together with addition, operations <code>double</code>,which doubles an integer, and <code>halve</code>, which divides an (even)integer by 2.  Using these, design a multiplication procedure analogousto <code>fast-expt</code> that uses a logarithmic number of steps.</p>
<p></p>
<p></p>
<p><a name="%_thm_1.18" id="%_thm_1.18"></a><b>Exercise 1.18.</b>  Using the results of exercises <a href="#%_thm_1.16">1.16</a>and <a href="#%_thm_1.17">1.17</a>, devise a procedure that generates an iterativeprocess for multiplying two integers in terms of adding, doubling, andhalving and uses a logarithmic number of steps.<a name="call_footnote_Temp_68" href="#footnote_Temp_68" id="call_footnote_Temp_68"><sup><small>40</small></sup></a></p>
<p></p>
<p></p>
<p><a name="%_thm_1.19" id="%_thm_1.19"></a><b>Exercise 1.19.</b>  <a name="%_idx_828" id="%_idx_828"></a>There is a clever algorithm for computing the Fibonacci numbers ina logarithmic number of steps.Recall the transformation of the state variables<em>a</em> and <em>b</em> in the <code>fib-iter</code> process ofsection <a href="#%_sec_1.2.2">1.2.2</a>: <em>a</em> ⟵  <em>a</em> + <em>b</em> and <em>b</em> ⟵<em>a</em>.  Call this transformation <em>T</em>, and observe that applying <em>T</em> overand over again <em>n</em> times, starting with 1 and 0, produces the pair <em>F</em><em>i</em><em>b</em>(<em>n</em> + 1) and  <em>F</em><em>i</em><em>b</em>(<em>n</em>).  In other words, the Fibonaccinumbers are produced by applying <em>T</em><sup><em>n</em></sup>, the <em>n</em>th power of thetransformation <em>T</em>, starting with the pair (1,0).  Now consider <em>T</em>to be the special case of <em>p</em> = 0 and <em>q</em> = 1 in a family oftransformations <em>T</em><sub><em>p</em><em>q</em></sub>, where <em>T</em><sub><em>p</em><em>q</em></sub> transforms the pair (<em>a</em>,<em>b</em>)according to <em>a</em> ⟵  <em>b</em><em>q</em> + <em>a</em><em>q</em> + <em>a</em><em>p</em> and <em>b</em> ⟵  <em>b</em><em>p</em> + <em>a</em><em>q</em>.  Showthat if we apply such a transformation <em>T</em><sub><em>p</em><em>q</em></sub> twice, the effect isthe same as using a single transformation <em>T</em><sub><em>p</em>'<em>q</em>'</sub> of the same form,and compute <em>p</em>' and <em>q</em>' in terms of <em>p</em> and <em>q</em>.  This gives us anexplicit way to square these transformations, and thus we can compute<em>T</em><sup><em>n</em></sup> using successive squaring, as in the <code>fast-expt</code>procedure.  Put this all together to complete the following procedure,which runs in a logarithmic number of steps:<a name="call_footnote_Temp_70" href="#footnote_Temp_70" id="call_footnote_Temp_70"><sup><small>41</small></sup></a></p>
<p></p>
<p></p>
<p><pre>(define (fib n)
  (fib-iter 1 0 0 1 n))
(define (fib-iter a b p q count)
  (cond ((= count 0) b)
        ((even? count)
         (fib-iter a
                   b
                   &lt;<em>??</em>&gt;      <em>; compute <em>p</em>'</em>
                   &lt;<em>??</em>&gt;      <em>; compute <em>q</em>'</em>
                   (/ count 2)))
        (else (fib-iter (+ (* b q) (* a q) (* a p))
                        (+ (* b p) (* a q))
                        p
                        q
                        (- count 1)))))
</pre></p>
<p></p>
<p></p>
<p></p>
<p><a name="%_sec_1.2.5" id="%_sec_1.2.5"></a></p>
<h3><a href="book-Z-H-4.html#%_toc_%_sec_1.2.5">1.2.5  Greatest Common Divisors</a></h3>
<p><a name="%_idx_834" id="%_idx_834"></a>The greatest common divisor (GCD) of two integers <em>a</em> and <em>b</em> isdefined to be the largest integer that divides both <em>a</em> and<em>b</em> with no remainder.  For example, the GCD of 16 and 28 is 4.  In chapter 2,when we investigate how to implement rational-number arithmetic, wewill need to be able to compute GCDs in order to reducerational numbers to lowest terms.  (To reduce a rational number tolowest terms, we must divide both the numerator and the denominator by theirGCD.  For example, 16/28 reduces to 4/7.)  One way to find theGCD of two integers is to factor them and search for commonfactors, but there is a famous algorithm that is much more efficient.</p>
<p><a name="%_idx_836" id="%_idx_836"></a>The idea of the algorithm is based on the observation that, if <em>r</em> isthe remainder when <em>a</em> is divided by <em>b</em>, then the common divisors of<em>a</em> and <em>b</em> are precisely the same as the common divisors of <em>b</em> and<em>r</em>.  Thus, we can use the equation</p><p><code>GCD(<em>a</em>, <em>b</em>) = GCD(<em>b</em>, <em>r</em>)</code></p>to successively reduce the problem of computing a GCD to theproblem of computing the GCD of smaller and smaller pairs ofintegers.  For example,<pre>GCD(206, 40) = GCD(40, 6)             = GCD(6, 4)             = GCD(4, 2)             = GCD(2, 0)             = 2</pre><p>reduces GCD(206,40) to GCD(2,0), which is 2.  It ispossible to show that starting with any two positive integers andperforming repeated reductions will always eventually produce a pairwhere the second number is 0.  Then the GCD is the othernumber in the pair.  This method for computing the GCD isknown as <em>Euclid's Algorithm</em>.<a name="call_footnote_Temp_71" href="#footnote_Temp_71" id="call_footnote_Temp_71"><sup><small>42</small></sup></a></p>
<p>It is easy to express Euclid's Algorithm as a procedure:</p>
<p></p>
<p><pre><a name="%_idx_842" id="%_idx_842"></a>(define (gcd a b)
  (if (= b 0)
      a
      (gcd b (remainder a b))))
</pre></p>
<p></p>
<p>This generates an iterative process, whose number of steps grows asthe logarithm of the numbers involved.</p>
<p><a name="%_idx_844" id="%_idx_844"></a>The fact that the number of steps required by Euclid's Algorithm haslogarithmic growth bears an interesting relation to the Fibonaccinumbers:</p>
<p></p>
<p></p>
<p><a name="%_idx_846" id="%_idx_846"></a><a name="%_idx_848" id="%_idx_848"></a><strong>Lamé's Theorem:</strong> If Euclid's Algorithm requires <em>k</em> steps tocompute the GCD of some pair, then the smaller number in the pairmust be greater than or equal to the <em>k</em>th Fibonaccinumber.<a name="call_footnote_Temp_72" href="#footnote_Temp_72" id="call_footnote_Temp_72"><sup><small>43</small></sup></a></p>
<p></p>
<p></p>
<p></p>
<p>We can use this theorem to get an order-of-growth estimate for Euclid'sAlgorithm.  Let <em>n</em> be the smaller of the two inputs to theprocedure.  If the process takes <em>k</em> steps, then we must have<em>n</em><u>&gt;</u>  <em>F</em><em>i</em><em>b</em> (<em>k</em>) ≈ <em>φ</em><sup><em>k</em></sup>/√5.  Thereforethe number of steps <em>k</em> grows as the logarithm (to the base<em>φ</em>) of <em>n</em>.  Hence, the order of growth is θ(<code>log</code> <em>n</em>).</p>
<p></p>
<p><a name="%_thm_1.20" id="%_thm_1.20"></a><b>Exercise 1.20.</b>  <a name="%_idx_852" id="%_idx_852"></a><a name="%_idx_854" id="%_idx_854"></a>The process that a procedure generates is of course dependent on therules used by the interpreter.  As an example, consider the iterative<code>gcd</code> procedure given above.Suppose we were to interpret this procedure using normal-orderevaluation, as discussed in section <a href="book-Z-H-10.html#%_sec_1.1.5">1.1.5</a>.(The normal-order-evaluation rule for <code>if</code> is described inexercise <a href="book-Z-H-10.html#%_thm_1.5">1.5</a>.)  Using thesubstitution method (for normal order), illustrate the processgenerated in evaluating <code>(gcd 206 40)</code> and indicate the<code>remainder</code> operations that are actually performed.How many <code>remainder</code> operations are actually performedin the normal-order evaluation of <code>(gcd 206 40)</code>?In the applicative-order evaluation?</p>
<p></p>
<p><a name="%_sec_1.2.6" id="%_sec_1.2.6"></a></p>
<h3><a href="book-Z-H-4.html#%_toc_%_sec_1.2.6">1.2.6  Example: Testing for Primality</a></h3>
<p><a name="%_idx_856" id="%_idx_856"></a><a name="%_idx_858" id="%_idx_858"></a>This section describes two methods for checking the primality of aninteger <em>n</em>, one with order of growth θ(√<em>n</em>), and a“probabilistic” algorithm with order of growth θ(<code>log</code> <em>n</em>).  Theexercises at the end of this section suggest programmingprojects based on these algorithms.</p>
<p><a name="%_sec_Temp_74" id="%_sec_Temp_74"></a></p>
<h4><a href="book-Z-H-4.html#%_toc_%_sec_Temp_74">Searching for divisors</a></h4>
<p>Since ancient times, mathematicians have been fascinated by problemsconcerning prime numbers, and many people have worked on the problemof determining ways to test if numbers are prime.  One wayto test if a number is prime is to find the number's divisors.  Thefollowing program finds the smallest integral divisor (greater than 1)of a given number <em>n</em>.  It does this in a straightforward way, bytesting <em>n</em> for divisibility by successive integers starting with 2.</p>
<p></p>
<p></p>
<p><pre><a name="%_idx_860" id="%_idx_860"></a>(define (smallest-divisor n)
  (find-divisor n 2))
<a name="%_idx_862" id="%_idx_862"></a>(define (find-divisor n test-divisor)
  (cond ((&gt; (square test-divisor) n) n)
        ((divides? test-divisor n) test-divisor)
        (else (find-divisor n (+ test-divisor 1)))))
<a name="%_idx_864" id="%_idx_864"></a>(define (divides? a b)
  (= (remainder b a) 0))
</pre></p>
<p></p>
<p></p>
<p>We can test whether a number is prime as follows: <em>n</em> is prime ifand only if <em>n</em> is its own smallest divisor.</p>
<p></p>
<p></p>
<p><pre><a name="%_idx_866" id="%_idx_866"></a>(define (prime? n)
  (= n (smallest-divisor n)))
</pre></p>
<p></p>
<p></p>
<p>The end test for <code>find-divisor</code> is based on the fact that if <em>n</em>is not prime it must have a divisor less than or equal to√<em>n</em>.<a name="call_footnote_Temp_75" href="#footnote_Temp_75" id="call_footnote_Temp_75"><sup><small>44</small></sup></a>  Thismeans that the algorithm need only test divisors between 1 and√<em>n</em>.  Consequently, the number of steps required to identify<em>n</em> as prime will have order of growth θ(√<em>n</em>).</p>
<p><a name="%_sec_Temp_76" id="%_sec_Temp_76"></a></p>
<h4><a href="book-Z-H-4.html#%_toc_%_sec_Temp_76">The Fermat test</a></h4>
<p><a name="%_idx_868" id="%_idx_868"></a><a name="%_idx_870" id="%_idx_870"></a>The θ(<code>log</code> <em>n</em>) primality test is based on a result from numbertheory known as Fermat's Little Theorem.<a name="call_footnote_Temp_77" href="#footnote_Temp_77" id="call_footnote_Temp_77"><sup><small>45</small></sup></a></p>
<p></p>
<p></p>
<p><a name="%_idx_886" id="%_idx_886"></a><strong>Fermat's Little Theorem:</strong> If <em>n</em> is a prime number and<em>a</em> is any positive integer less than <em>n</em>, then <em>a</em> raised to the<em>n</em>th power is congruent to <em>a</em> modulo <em>n</em>.</p>
<p></p>
<p></p>
<p><a name="%_idx_888" id="%_idx_888"></a>(Two numbers are said to be <em>congruent modulo</em> <em>n</em> ifthey both have the same remainder when divided by <em>n</em>.  Theremainder of a number <em>a</em> when divided by <em>n</em> is also referred to asthe <a name="%_idx_890" id="%_idx_890"></a><a name="%_idx_892" id="%_idx_892"></a><em>remainder of</em> <em>a</em> <em>modulo</em> <em>n</em>, or simply as <em>a</em><em>modulo</em> <em>n</em>.)</p>
<p>If <em>n</em> is not prime, then, in general, most of the numbers <em>a</em>&lt; <em>n</em> will notsatisfy the above relation.  This leads to the following algorithm fortesting primality: Given a number <em>n</em>, pick a <a name="%_idx_894" id="%_idx_894"></a>random number <em>a</em> &lt; <em>n</em> andcompute the remainder of <em>a</em><sup><em>n</em></sup> modulo <em>n</em>.  If the result is not equal to<em>a</em>, then <em>n</em> is certainly not prime.  If it is <em>a</em>, then chances are goodthat <em>n</em> is prime.  Now pick another random number <em>a</em> and test it with thesame method.  If it also satisfies the equation, then we can be even moreconfident that <em>n</em> is prime.  By trying more and more values of <em>a</em>, we canincrease our confidence in the result.  This algorithm is known as theFermat test.</p>
<p><a name="%_idx_896" id="%_idx_896"></a>To implement the Fermat test, we need a procedure that computes theexponential of a number modulo another number:</p>
<p></p>
<p></p>
<p><pre><a name="%_idx_898" id="%_idx_898"></a>(define (expmod base exp m)
  (cond ((= exp 0) 1)
        ((even? exp)
         (remainder (square (expmod base (/ exp 2) m))
                    m))
        (else
         (remainder (* base (expmod base (- exp 1) m))
                    m))))        
</pre></p>
<p></p>
<p>This is very similar to the <code>fast-expt</code> procedure ofsection <a href="#%_sec_1.2.4">1.2.4</a>.  It uses successive squaring, sothat the number of steps grows logarithmically with theexponent.<a name="call_footnote_Temp_78" href="#footnote_Temp_78" id="call_footnote_Temp_78"><sup><small>46</small></sup></a></p>
<p>The Fermat test is performed by choosing at random a number <em>a</em>between 1 and <em>n</em> - 1 inclusive and checking whether the remaindermodulo <em>n</em> of the <em>n</em>th power of <em>a</em> is equal to <em>a</em>.  The randomnumber <em>a</em> is chosen using the procedure <a name="%_idx_900" id="%_idx_900"></a><a name="%_idx_902" id="%_idx_902"></a><code>random</code>, which we assume isincluded as a primitive in Scheme. <code>Random</code> returns anonnegative integer less than its integer input.  Hence, to obtain a randomnumber between 1 and <em>n</em> - 1, we call <code>random</code> with an input of<em>n</em> - 1 and add 1 to the result:</p>
<p></p>
<p></p>
<p><pre><a name="%_idx_904" id="%_idx_904"></a>(define (fermat-test n)
  (define (try-it a)
    (= (expmod a n n) a))
  (try-it (+ 1 (random (- n 1)))))
</pre></p>
<p></p>
<p></p>
<p>The following procedure runs the test a given number of times, asspecified by a parameter.  Its value is true if the test succeedsevery time, and false otherwise.</p>
<p></p>
<p></p>
<p><pre><a name="%_idx_906" id="%_idx_906"></a>(define (fast-prime? n times)
  (cond ((= times 0) true)
        ((fermat-test n) (fast-prime? n (- times 1)))
        (else false)))
</pre></p>
<p></p>
<p></p>
<p><a name="%_sec_Temp_79" id="%_sec_Temp_79"></a></p>
<h4><a href="book-Z-H-4.html#%_toc_%_sec_Temp_79">Probabilistic methods</a></h4>
<p><a name="%_idx_908" id="%_idx_908"></a><a name="%_idx_910" id="%_idx_910"></a>The Fermat test differs in character from most familiar algorithms, inwhich one computes an answer that is guaranteed to be correct.  Here,the answer obtained is only probably correct.  More precisely, if <em>n</em>ever fails the Fermat test, we can be certain that <em>n</em> is not prime.But the fact that <em>n</em> passes the test, while an extremely strongindication, is still not a guarantee that <em>n</em> is prime.  What we wouldlike to say is that for any number <em>n</em>, if we perform the test enoughtimes and find that <em>n</em> always passes the test, then the probabilityof error in our primality test can be made as small as we like.</p>
<p>Unfortunately, this assertion is not quite correct.  There do existnumbers that fool the Fermat test: numbers <em>n</em> that are not prime andyet have the property that <em>a</em><sup><em>n</em></sup> is congruent to <em>a</em> modulo <em>n</em> forall integers <em>a</em> &lt; <em>n</em>.  Such numbers are extremely rare, so the Fermattest is quite reliable in practice.<a name="call_footnote_Temp_80" href="#footnote_Temp_80" id="call_footnote_Temp_80"><sup><small>47</small></sup></a>There are variations of the Fermat test that cannot be fooled.  Inthese tests, as with the Fermat method, one tests the primality of aninteger <em>n</em> by choosing a random integer <em>a</em>&lt;<em>n</em> and checking somecondition that depends upon <em>n</em> and <em>a</em>.  (Seeexercise <a href="#%_thm_1.28">1.28</a> for an example of such a test.)  On theother hand, in contrast to the Fermat test, one can prove that, forany <em>n</em>, the condition does not hold for most of the integers <em>a</em>&lt;<em>n</em>unless <em>n</em> is prime.  Thus, if <em>n</em> passes the test for some randomchoice of <em>a</em>, the chances are better than even that <em>n</em> is prime.  If<em>n</em> passes the test for two random choices of <em>a</em>, the chances are betterthan 3 out of 4 that <em>n</em> is prime. By running the test with more andmore randomly chosen values of <em>a</em> we can make the probability oferror as small as we like.</p>
<p>The existence of tests for which one can prove that the chance oferror becomes arbitrarily small has sparked interest in algorithms ofthis type, which have come to be known as <em>probabilisticalgorithms</em>.  There is a great deal of research activity in this area,and probabilistic algorithms have been fruitfully applied to manyfields.<a name="call_footnote_Temp_81" href="#footnote_Temp_81" id="call_footnote_Temp_81"><sup><small>48</small></sup></a></p>
<p></p>
<p><a name="%_thm_1.21" id="%_thm_1.21"></a><b>Exercise 1.21.</b>  Use the <code>smallest-divisor</code> procedure to find the smallest divisorof each of the following numbers: 199, 1999, 19999.</p>
<p></p>
<p></p>
<p><a name="%_thm_1.22" id="%_thm_1.22"></a><b>Exercise 1.22.</b>  <a name="%_idx_932" id="%_idx_932"></a><a name="%_idx_934" id="%_idx_934"></a>Most Lisp implementations include a primitive called <code>runtime</code>that returns an integer that specifies the amount of time the systemhas been running (measured, for example, in microseconds).  Thefollowing <code>timed-prime-test</code> procedure, when called with aninteger <em>n</em>, prints <em>n</em> and checks to see if <em>n</em> is prime.  If <em>n</em> isprime, the procedure prints three asterisks followed by the amount of timeused in performing the test.</p>
<p></p>
<p></p>
<p><pre><a name="%_idx_936" id="%_idx_936"></a><a name="%_idx_938" id="%_idx_938"></a><a name="%_idx_940" id="%_idx_940"></a>(define (timed-prime-test n)
  (newline)
  (display n)
  (start-prime-test n (runtime)))
(define (start-prime-test n start-time)
  (if (prime? n)
      (report-prime (- (runtime) start-time))))
(define (report-prime elapsed-time)
  (display " *** ")
  (display elapsed-time))
</pre></p>
<p></p>
<p>Using this procedure, write a procedure <code>search-for-primes</code> thatchecks the primality of consecutive odd integers in a specified range.Use your procedure to find the three smallest primes larger than 1000;larger than 10,000; larger than 100,000; larger than 1,000,000.  Notethe time needed to test each prime.  Since the testing algorithm hasorder of growth of θ(√<em>n</em>), you should expect that testingfor primes around 10,000 should take about √10 times as longas testing for primes around 1000.  Do your timing data bear this out?How well do the data for 100,000 and 1,000,000 support the √<em>n</em>prediction?  Is your result compatible with the notion that programson your machine run in time proportional to the number of stepsrequired for the computation?</p>
<p></p>
<p></p>
<p><a name="%_thm_1.23" id="%_thm_1.23"></a><b>Exercise 1.23.</b>  <a name="%_idx_942" id="%_idx_942"></a>The <code>smallest-divisor</code> procedure shown at the start of this sectiondoes lots of needless testing: After it checks to see if thenumber is divisible by 2 there is no point in checking to see ifit is divisible by any larger even numbers.  This suggests that thevalues used for <code>test-divisor</code> should not be 2, 3, 4, 5, 6,<code>...</code>, but rather 2, 3, 5, 7, 9, <code>...</code>.  To implement thischange, define a procedure <code>next</code> that returns 3 if its input isequal to 2 and otherwise returns its input plus 2.  Modify the <code>smallest-divisor</code> procedure to use <code>(next test-divisor)</code> insteadof <code>(+ test-divisor 1)</code>.  With <code>timed-prime-test</code>incorporating this modified version of <code>smallest-divisor</code>, run thetest for each of the 12 primes found inexercise <a href="#%_thm_1.22">1.22</a>.  Since this modification halves thenumber of test steps, you should expect it to run about twice as fast.Is this expectation confirmed?  If not, what is the observed ratio ofthe speeds of the two algorithms, and how do you explain the fact thatit is different from 2?</p>
<p></p>
<p></p>
<p><a name="%_thm_1.24" id="%_thm_1.24"></a><b>Exercise 1.24.</b>  Modify the <code>timed-prime-test</code> procedure ofexercise <a href="#%_thm_1.22">1.22</a> to use <code>fast-prime?</code> (theFermat method), and test each of the 12 primes you found in thatexercise.  Since the Fermat test has θ(<code>log</code> <em>n</em>) growth, howwould you expect the time to test primes near 1,000,000 to comparewith the time needed to test primes near 1000?  Do your data bear thisout?  Can you explain any discrepancy you find?</p>
<p></p>
<p></p>
<p><a name="%_thm_1.25" id="%_thm_1.25"></a><b>Exercise 1.25.</b>  Alyssa P. Hacker complains that we went to a lot of extra work inwriting <code>expmod</code>.  After all, she says, since we already know howto compute exponentials, we could have simply written</p>
<p></p>
<p></p>
<p><pre><a name="%_idx_944" id="%_idx_944"></a>(define (expmod base exp m)
  (remainder (fast-expt base exp) m))
</pre></p>
<p></p>
<p>Is she correct?  Would this procedure serve as well for our fast primetester?  Explain.</p>
<p></p>
<p></p>
<p><a name="%_thm_1.26" id="%_thm_1.26"></a><b>Exercise 1.26.</b>  Louis Reasoner is having great difficulty doingexercise <a href="#%_thm_1.24">1.24</a>.  His <code>fast-prime?</code> testseems to run more slowly than his <code>prime?</code> test.  Louis calls hisfriend Eva Lu Ator over to help.  When they examine Louis's code, theyfind that he has rewritten the <code>expmod</code> procedure to use anexplicit multiplication, rather than calling <code>square</code>:</p>
<p></p>
<p></p>
<p><pre><a name="%_idx_946" id="%_idx_946"></a>(define (expmod base exp m)
  (cond ((= exp 0) 1)
        ((even? exp)
         (remainder (* (expmod base (/ exp 2) m)
                       (expmod base (/ exp 2) m))
                    m))
        (else
         (remainder (* base (expmod base (- exp 1) m))
                    m))))
</pre></p>
<p></p>
<p>“I don't see what difference that could make,” says Louis.  “Ido.”  says Eva.  “By writing the procedure like that, you havetransformed the θ(<code>log</code> <em>n</em>) process into a θ(<em>n</em>) process.”Explain.</p>
<p></p>
<p></p>
<p><a name="%_thm_1.27" id="%_thm_1.27"></a><b>Exercise 1.27.</b>  <a name="%_idx_948" id="%_idx_948"></a>Demonstrate that the Carmichael numbers listed infootnote <a href="#footnote_Temp_80">47</a> really do foolthe Fermat test.  That is, write a procedure that takes an integer <em>n</em>and tests whether <em>a</em><sup><em>n</em></sup> is congruent to <em>a</em> modulo <em>n</em> for every<em>a</em>&lt;<em>n</em>, and try your procedure on the given Carmichael numbers.</p>
<p></p>
<p></p>
<p><a name="%_thm_1.28" id="%_thm_1.28"></a><b>Exercise 1.28.</b>  <a name="%_idx_950" id="%_idx_950"></a><a name="%_idx_952" id="%_idx_952"></a><a name="%_idx_954" id="%_idx_954"></a><a name="%_idx_956" id="%_idx_956"></a><a name="%_idx_958" id="%_idx_958"></a>One variant of the Fermat test that cannot be fooled is called the<em>Miller-Rabin test</em> (Miller 1976; Rabin 1980).  This starts from<a name="%_idx_960" id="%_idx_960"></a>an alternate form of Fermat's Little Theorem, which states that if <em>n</em>is a prime number and <em>a</em> is any positive integer less than <em>n</em>, then<em>a</em> raised to the (<em>n</em> - 1)st power is congruent to 1 modulo <em>n</em>.  To testthe primality of a number <em>n</em> by the Miller-Rabin test, we pick arandom number <em>a</em>&lt;<em>n</em> and raise <em>a</em> to the (<em>n</em> - 1)st power modulo <em>n</em>using the <code>expmod</code> procedure.  However, whenever we perform thesquaring step in <code>expmod</code>, we check to see if we have discovered a“nontrivial square root of 1 modulo <em>n</em>,” that is, a number notequal to 1 or <em>n</em> - 1 whose square is equal to 1 modulo <em>n</em>.  It ispossible to prove that if such a nontrivial square root of 1 exists,then <em>n</em> is not prime.  It is also possible to prove that if <em>n</em> is anodd number that is not prime, then, for at least half the numbers<em>a</em>&lt;<em>n</em>, computing <em>a</em><sup><em>n</em>-1</sup> in this way will reveal a nontrivialsquare root of 1 modulo <em>n</em>.  (This is why the Miller-Rabin testcannot be fooled.)  Modify the <code>expmod</code> procedure to signal if itdiscovers a nontrivial square root of 1, and use this to implementthe Miller-Rabin test with a procedure analogous to <code>fermat-test</code>.Check your procedure by testing various known primes and non-primes.Hint: One convenient way to make <code>expmod</code> signal is to have itreturn 0.</p>
<p></p>
<p></p>
<p></p>
<div class="smallprint"><hr></div>
<p></p>
<div class="footnote">
<p><a name="footnote_Temp_46" href="#call_footnote_Temp_46" id="footnote_Temp_46"><sup><small>29</small></sup></a> In a real program we would probably use theblock structure introduced in the last section to hide the definitionof <code>fact-iter</code>:</p>
<p></p>
<p><pre>(define (factorial n)
  (define (iter product counter)
    (if (&gt; counter n)
        product
        (iter (* counter product)
              (+ counter 1))))
  (iter 1 1))
</pre></p>
<p></p>
<p>We avoided doing this here so as to minimize the number of things tothink about at once.</p>
<p><a name="footnote_Temp_47" href="#call_footnote_Temp_47" id="footnote_Temp_47"><sup><small>30</small></sup></a> When we discuss the implementation ofprocedures on register machines in chapter 5, we will see that anyiterative process can be realized “in hardware” as a machine thathas a fixed set of registers and no auxiliary memory.  In contrast,realizing a recursive process requires a machine that uses an<a name="%_idx_678" id="%_idx_678"></a>auxiliary data structure known as a <em>stack</em>.</p>
<p><a name="footnote_Temp_48" href="#call_footnote_Temp_48" id="footnote_Temp_48"><sup><small>31</small></sup></a> Tail recursion has long been<a name="%_idx_698" id="%_idx_698"></a><a name="%_idx_700" id="%_idx_700"></a><a name="%_idx_702" id="%_idx_702"></a>known as a compiler optimization trick.  A coherent semantic basis fortail recursion was provided by Carl Hewitt (1977), who explained it in<a name="%_idx_704" id="%_idx_704"></a>terms of the “message-passing” model of computation that we shalldiscuss in chapter 3. Inspired by this, Gerald Jay Sussman and GuyLewis Steele Jr. (see Steele 1975) constructed a tail-recursiveinterpreter for Scheme.  Steele later showed how tail recursion is aconsequence of the natural way to compile procedure calls (Steele1977).  The IEEE standard for Scheme requires that Scheme implementations<a name="%_idx_706" id="%_idx_706"></a>be tail-recursive.</p>
<p><a name="footnote_Temp_51" href="#call_footnote_Temp_51" id="footnote_Temp_51"><sup><small>32</small></sup></a> An example of this was hintedat in section <a href="book-Z-H-10.html#%_sec_1.1.3">1.1.3</a>:The interpreter itself evaluates expressionsusing a tree-recursive process.</p>
<p><a name="footnote_Temp_53" href="#call_footnote_Temp_53" id="footnote_Temp_53"><sup><small>33</small></sup></a> For example, work through in detail how thereduction rule applies to the problem of making change for 10 centsusing pennies and nickels.</p>
<p><a name="footnote_Temp_54" href="#call_footnote_Temp_54" id="footnote_Temp_54"><sup><small>34</small></sup></a> Oneapproach to coping with redundant computations is to arrange mattersso that we automatically construct a table of values as theyare computed.  Each time we are asked to apply the procedure to someargument, we first look to see if the value is already stored in thetable, in which case we avoid performing the redundant computation.This strategy, known as <a name="%_idx_734" id="%_idx_734"></a><a name="%_idx_736" id="%_idx_736"></a><em>tabulation</em> or <em>memoization</em>, can beimplemented in a straightforward way.  Tabulation can sometimes beused to transform processes that require an exponential number ofsteps (such as <code>count-change</code>) into processes whose space and timerequirements grow linearly with the input.  Seeexercise <a href="book-Z-H-22.html#%_thm_3.27">3.27</a>.</p>
<p><a name="footnote_Temp_57" href="#call_footnote_Temp_57" id="footnote_Temp_57"><sup><small>35</small></sup></a> The elements of Pascal's triangle are called the <em>binomialcoefficients</em>, because the <em>n</em>th row consists of<a name="%_idx_740" id="%_idx_740"></a>the coefficients of the terms in theexpansion of (<em>x</em> + <em>y</em>)<sup><em>n</em></sup>.  This pattern for computing the coefficients<a name="%_idx_742" id="%_idx_742"></a>appeared in Blaise Pascal's 1653 seminal work on probability theory, <em>Traité du triangle arithmétique</em>.  According to<a name="%_idx_744" id="%_idx_744"></a>Knuth (1973), the same pattern appears in the <em>Szu-yuenYü-chien</em> (“The Precious Mirror of the Four Elements”), published<a name="%_idx_746" id="%_idx_746"></a><a name="%_idx_748" id="%_idx_748"></a><a name="%_idx_750" id="%_idx_750"></a>by the Chinese mathematician Chu Shih-chieh in 1303, in theworks of the twelfth-century Persian poet and mathematician OmarKhayyam, and in the works of the twelfth-century Hindu mathematicianBháscara Áchárya.</p>
<p><a name="footnote_Temp_59" href="#call_footnote_Temp_59" id="footnote_Temp_59"><sup><small>36</small></sup></a> These statements mask agreat deal of oversimplification.  For instance, if we count processsteps as “machine operations” we are making the assumption that thenumber of machine operations needed to perform, say, a multiplicationis independent of the size of the numbers to be multiplied, which isfalse if the numbers are sufficiently large.  Similar remarks hold forthe estimates of space.  Like the design and description of a process,the analysis of a process can be carried out at various levels ofabstraction.</p>
<p><a name="footnote_Temp_62" href="#call_footnote_Temp_62" id="footnote_Temp_62"><sup><small>37</small></sup></a> More precisely, the number of multiplicationsrequired is equal to 1 less than the log base 2 of <em>n</em> plus the numberof ones in the binary representation of <em>n</em>.  This total is alwaysless than twice the log base 2 of <em>n</em>.  The arbitrary constants<em>k</em><sub>1</sub> and <em>k</em><sub>2</sub> inthe definition of order notation imply that, for a logarithmicprocess, the base to which logarithms are taken does not matter, soall such processes are described as θ(<code>log</code> <em>n</em>).</p>
<p><a name="footnote_Temp_63" href="#call_footnote_Temp_63" id="footnote_Temp_63"><sup><small>38</small></sup></a> You may wonderwhy anyone would care about raising numbers to the 1000th power.  Seesection <a href="#%_sec_1.2.6">1.2.6</a>.</p>
<p><a name="footnote_Temp_64" href="#call_footnote_Temp_64" id="footnote_Temp_64"><sup><small>39</small></sup></a> This iterativealgorithm is ancient.  It appears in the <em>Chandah-sutra</em> by<a name="%_idx_810" id="%_idx_810"></a><a name="%_idx_812" id="%_idx_812"></a><a name="%_idx_814" id="%_idx_814"></a>Áchárya Pingala, written before 200 <font size="-2">B</font>.<font size="-2">C</font>. See Knuth 1981, section4.6.3, for a full discussion and analysis of this and other methods ofexponentiation.</p>
<p><a name="footnote_Temp_68" href="#call_footnote_Temp_68" id="footnote_Temp_68"><sup><small>40</small></sup></a> This<a name="%_idx_820" id="%_idx_820"></a><a name="%_idx_822" id="%_idx_822"></a>algorithm, which is sometimes known as the “Russian peasant method”of multiplication, is ancient.  Examples of its use are found in the<a name="%_idx_824" id="%_idx_824"></a>Rhind Papyrus, one of the two oldest mathematical documents inexistence, written about 1700 <font size="-2">B</font>.<font size="-2">C</font>. (and copied from an even<a name="%_idx_826" id="%_idx_826"></a>older document) by an Egyptian scribe named A'h-mose.</p>
<p><a name="footnote_Temp_70" href="#call_footnote_Temp_70" id="footnote_Temp_70"><sup><small>41</small></sup></a> This exercise was<a name="%_idx_830" id="%_idx_830"></a><a name="%_idx_832" id="%_idx_832"></a>suggested to us by Joe Stoy, based on an example in Kaldewaij 1990.</p>
<p><a name="footnote_Temp_71" href="#call_footnote_Temp_71" id="footnote_Temp_71"><sup><small>42</small></sup></a> Euclid's Algorithm is so<a name="%_idx_838" id="%_idx_838"></a>called because it appears in Euclid's <em>Elements</em> (Book 7, ca. 300<font size="-2">B</font>.<font size="-2">C</font>.).  According to Knuth (1973), it can be considered the<a name="%_idx_840" id="%_idx_840"></a>oldest known nontrivial algorithm.  The ancient Egyptian method ofmultiplication (exercise <a href="#%_thm_1.18">1.18</a>) is surely older,but, as Knuth explains, Euclid's algorithm is the oldest known to havebeen presented as a general algorithm, rather than as a set ofillustrative examples.</p>
<p><a name="footnote_Temp_72" href="#call_footnote_Temp_72" id="footnote_Temp_72"><sup><small>43</small></sup></a> This theorem was proved in 1845 by Gabriel Lamé, a<a name="%_idx_850" id="%_idx_850"></a>French mathematician and engineer known chiefly for his contributionsto mathematical physics.  To prove the theorem, we consider pairs(<em>a</em><sub><em>k</em></sub> ,<em>b</em><sub><em>k</em></sub>), where <em>a</em><sub><em>k</em></sub><u>&gt;</u> <em>b</em><sub><em>k</em></sub>, for which Euclid's Algorithmterminates in <em>k</em> steps.  The proof is based on the claim that, if(<em>a</em><sub><em>k</em>+1</sub>, <em>b</em><sub><em>k</em>+1</sub>)  ⟶  (<em>a</em><sub><em>k</em></sub>, <em>b</em><sub><em>k</em></sub>) ⟶  (<em>a</em><sub><em>k</em>-1</sub>, <em>b</em><sub><em>k</em>-1</sub>) are three successive pairs in thereduction process, then we must have <em>b</em><sub><em>k</em>+1</sub><u>&gt;</u> <em>b</em><sub><em>k</em></sub>  +  <em>b</em><sub><em>k</em>-1</sub>.To verify the claim, consider that a reduction step is defined byapplying the transformation <em>a</em><sub><em>k</em>-1</sub>  =  <em>b</em><sub><em>k</em></sub>, <em>b</em><sub><em>k</em>-1</sub>  = remainder of  <em>a</em><sub><em>k</em></sub> divided by <em>b</em><sub><em>k</em></sub>.The second equation means that <em>a</em><sub><em>k</em></sub>  =  <em>q</em><em>b</em><sub><em>k</em></sub>  +  <em>b</em><sub><em>k</em>-1</sub> for somepositive integer <em>q</em>.  And since <em>q</em> must be at least 1 we have <em>a</em><sub><em>k</em></sub> =  <em>q</em><em>b</em><sub><em>k</em></sub>  +  <em>b</em><sub><em>k</em>-1</sub><u>&gt;</u> <em>b</em><sub><em>k</em></sub>  +  <em>b</em><sub><em>k</em>-1</sub>.  But in the previousreduction step we have <em>b</em><sub><em>k</em>+1</sub> =  <em>a</em><sub><em>k</em></sub>.  Therefore, <em>b</em><sub><em>k</em>+1</sub>  =<em>a</em><sub><em>k</em></sub><u>&gt;</u> <em>b</em><sub><em>k</em></sub>  +  <em>b</em><sub><em>k</em>-1</sub>.  This verifies the claim.  Now we canprove the theorem by induction on <em>k</em>, the number of steps that thealgorithm requires to terminate.  The result is true for <em>k</em> = 1, sincethis merely requires that <em>b</em> be at least as large as<em>F</em><em>i</em><em>b</em>(1) = 1.  Now, assume that the result is true for all integers lessthan or equal to <em>k</em> and establish the result for <em>k</em> + 1.  Let(<em>a</em><sub><em>k</em>+1</sub>, <em>b</em><sub><em>k</em>+1</sub>) ⟶ (<em>a</em><sub><em>k</em></sub>, <em>b</em><sub><em>k</em></sub>) ⟶ (<em>a</em><sub><em>k</em>-1</sub>, <em>b</em><sub><em>k</em>-1</sub>) be successive pairs in thereduction process.  By our induction hypotheses, we have <em>b</em><sub><em>k</em>-1</sub><u>&gt;</u> <em>F</em><em>i</em><em>b</em>(<em>k</em> - 1) and <em>b</em><sub><em>k</em></sub><u>&gt;</u>  <em>F</em><em>i</em><em>b</em>(<em>k</em>).  Thus, applying the claim we justproved together with the definition of the Fibonacci numbers gives<em>b</em><sub><em>k</em>+1</sub><u>&gt;</u> <em>b</em><sub><em>k</em></sub>  +  <em>b</em><sub><em>k</em>-1</sub><u>&gt;</u>  <em>F</em><em>i</em><em>b</em>(<em>k</em>)  +   <em>F</em><em>i</em><em>b</em>(<em>k</em> - 1)  =  <em>F</em><em>i</em><em>b</em>(<em>k</em> + 1), whichcompletes the proof of Lamé's Theorem.</p>
<p><a name="footnote_Temp_75" href="#call_footnote_Temp_75" id="footnote_Temp_75"><sup><small>44</small></sup></a> If <em>d</em> is a divisor of <em>n</em>, then so is <em>n</em>/<em>d</em>.But <em>d</em> and <em>n</em>/<em>d</em> cannot both be greater than √<em>n</em>.</p>
<p><a name="footnote_Temp_77" href="#call_footnote_Temp_77" id="footnote_Temp_77"><sup><small>45</small></sup></a> Pierre de Fermat (1601-1665) is considered to be the founder of<a name="%_idx_872" id="%_idx_872"></a><a name="%_idx_874" id="%_idx_874"></a>modern number theory.  He obtained many important number-theoreticresults, but he usually announced just the results, without providinghis proofs.  <a name="%_idx_876" id="%_idx_876"></a>Fermat's Little Theorem was stated in a letter he wrote in1640.  The first published proof was given by <a name="%_idx_878" id="%_idx_878"></a>Euler in 1736 (and an<a name="%_idx_880" id="%_idx_880"></a>earlier, identical proof was discovered in the unpublished manuscriptsof Leibniz).  The most famous of Fermat's results – known as Fermat'sLast Theorem – was jotted down in 1637 in his copy of the book <em>Arithmetic</em> (by the third-century Greek mathematician <a name="%_idx_882" id="%_idx_882"></a>Diophantus) with theremark “I have discovered a truly remarkable proof, but this margin istoo small to contain it.”  Finding a proof of Fermat's Last Theorembecame one of the most famous challenges in number theory.  A complete<a name="%_idx_884" id="%_idx_884"></a>solution was finally given in 1995 by Andrew Wiles of Princeton University.</p>
<p><a name="footnote_Temp_78" href="#call_footnote_Temp_78" id="footnote_Temp_78"><sup><small>46</small></sup></a> The reduction steps in the cases where the exponent<em>e</em> is greater than 1 are based on the fact that, for any integers<em>x</em>, <em>y</em>, and <em>m</em>, we can find the remainder of <em>x</em> times <em>y</em> modulo<em>m</em> by computing separately the remainders of <em>x</em> modulo <em>m</em> and <em>y</em>modulo <em>m</em>, multiplying these, and then taking the remainder of theresult modulo <em>m</em>.  For instance, in the case where <em>e</em> is even, wecompute the remainder of <em>b</em><sup><em>e</em>/2</sup> modulo <em>m</em>, square this, and takethe remainder modulo <em>m</em>.  This technique is useful because it meanswe can perform our computation without ever having to deal withnumbers much larger than <em>m</em>.  (Compareexercise <a href="#%_thm_1.25">1.25</a>.)</p>
<p><a name="footnote_Temp_80" href="#call_footnote_Temp_80" id="footnote_Temp_80"><sup><small>47</small></sup></a> Numbers that fool the<a name="%_idx_912" id="%_idx_912"></a>Fermat test are called <em>Carmichael numbers</em>, and little is knownabout them other than that they are extremely rare.  There are 255Carmichael numbers below 100,000,000.  The smallest few are 561, 1105,1729, 2465, 2821, and 6601.  In testing primality of very largenumbers chosen at random, the chance of stumbling upon a value thatfools the Fermat test is less than the chance that <a name="%_idx_914" id="%_idx_914"></a>cosmic radiationwill cause the computer to make an error in carrying out a “correct”algorithm.  Considering an algorithm to be inadequate for the firstreason but not for the second illustrates the difference between<a name="%_idx_916" id="%_idx_916"></a><a name="%_idx_918" id="%_idx_918"></a>mathematics and engineering.</p>
<p><a name="footnote_Temp_81" href="#call_footnote_Temp_81" id="footnote_Temp_81"><sup><small>48</small></sup></a> One of the most striking applications of<a name="%_idx_920" id="%_idx_920"></a>probabilistic prime testing has been to the field of cryptography.Although it is now computationally infeasible to factor an arbitrary200-digit number, the primality of such a number can be checked in afew seconds with the Fermat test.  This fact forms the basis of atechnique for constructing “unbreakable codes” suggested by <a name="%_idx_922" id="%_idx_922"></a>Rivest,<a name="%_idx_924" id="%_idx_924"></a>Shamir, and <a name="%_idx_926" id="%_idx_926"></a>Adleman (1977).  The resulting <a name="%_idx_928" id="%_idx_928"></a><em>RSA algorithm</em> hasbecome a widely used technique for enhancing the security ofelectronic communications.  Because of this and related developments,the study of <a name="%_idx_930" id="%_idx_930"></a>prime numbers, once considered the epitome of a topic in“pure” mathematics to be studied only for its own sake, now turnsout to have important practical applications to cryptography,electronic funds transfer, and information retrieval.</p>
</div></body>
</html>
